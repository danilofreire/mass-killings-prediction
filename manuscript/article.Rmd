---
title:  |
        | Evaluating Empirical Explanations for State-Sponsored Violence with Ensemble Models
author: 
  - Danilo Freire[^danilo]
  - Gary Uzonyi[^gary]
date: \today
thanks: "We thank Toke Aidt, Giovana Fran√ßa, Lucas Mingardi, Robert McDonnell, Umberto Mignozzetti, Catarina Roman, David Skarbek, and Graham Denyer Willis for their helpful suggestions and comments. All replication materials are available at <https://github.com/danilofreire/mass-killings-prediction>."
abstract: "The literature on state-sponsored violence has grown significantly over the last decades. Although scholars have suggested a number of potential correlates of mass killings, it is unclear whether those factors increase our ability to forecast state-led violence. Here we employ ensemble learning algorithms to test the predictive performance of 40 variables on a sample of 177 countries from 1945 to 2013. We find that most variables fail to improve out-of-sample predictive power (*mention opportunity logic*). We also find high-order interactions between the covariates, which the existing literature generally does not account for. We argue that empirical studies on mass atrocities should adopt more flexible modelling techniques and use predictive accuracy to validate theories and inform public policy decisions."
abstractspacing: double
keywords: ensemble models, genocide, mass killings, random forests, state-sponsored violence
jelcodes: C52, C53, D74, H56, K10
fontsize: 12pt
margin: 2cm
urlcolor: darkblue
linkcolor: Mahogany
citecolor: Mahogany
spacing: double
papersize: a4paper
bibliography: references.bib
biblio-style: apalike
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    number_sections: yes
    keep_tex: no
    toc: no
    toc_depth: 3
    template: article-template.latex
---

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# If you need to install any package while knitting the document
r <- getOption("repos")
r["CRAN"] <- "https://cran.rstudio.com/"
options(repos = r)
if (!require("kableExtra")) {
    install.packages("kableExtra")
}
```

[^danilo]: Postdoctoral Research Associate, The Political Theory Project, Brown
University, 8 Fones Alley, Providence, RI 02912,
[`danilofreire@gmail.com`](mailto:danilofreire@gmail.com),
<http://danilofreire.github.io>. Corresponding author.

[^gary]: Assistant Professor, Department of Political Science; Research Fellow,
Howard H. Baker Jr. Center for Public Policy, University of Tennessee, 1640
Cumberland Ave, Knoxville, TN 37996,
[`guzonyi@utk.edu`](mailto:guzonyi@utk.edu),
<https://sites.google.com/site/uzonyigary>.

\newpage

# Introduction
\label{sec:intro}

Since the end of World War II, mass killings, genocides, and politicides have
claimed over 34.5 million lives [@marshall2017pitf].[^definition]
The international community has responded with an effort to prevent further
state-sponsored mass murder by strengthening laws against war crimes and crimes
against humanity. Furthermore, the United Nations established a Special Adviser
on the Prevention of Genocide and recognised its members' responsibility to
protect civilian populations within and outside their own borders. Yet, such
atrocities still occur. Recently, President al-Assad of Syria has massacred
tens of thousands of civilians during the Syrian Civil War [@goldman2017nyt].
Similarly, South Sudan's President Kiir is actively starving and killing
civilians from dissident and rival tribes [@nichols2017reuters]. While there is
some evidence that such atrocities may be declining since the Cold War
[@valentino2014we], the international community has been far from successful in
realising slogans like "Never Again" and "Not on My Watch" [@cheadle2007not].

[^definition]: Genocide and politicide are the attempted intentional
destruction of communal or political groups, respectively [see
@harff1988toward]. Mass killing includes these atrocities, as well as attacks
against civilians that result in at least 1,000 deaths but are not intended to
destroy a particular group [see @ulfelder2008assessing]. While some conflate
these types of atrocities [e.g., @rummel1995democracy; @valentino2004draining],
others claim genocide and politicide follow a different logic from other forms
of government violence [@kalyvas2006logic; @stanton2015regulating]. For
discussion on these important differences in conceptualisation see
@straus2007second and @finkel2012macro.

Ultimately, effective prevention requires us to infer when mass killings are
likely to occur. In this vein, the academic community suggests a myriad of
factors that correlate with government brutality, such as population dynamics,
military spending, trade indicators, and regime characteristics [e.g.,
@colaresi2008kill; @harff2003no; @krain1997state]. But despite the
rapid growth of the literature on mass atrocities, existing theories have not
been followed by systematic evaluations of their relative predictive
performance. With few notable exceptions, such as @ulfelder2008assessing and
@ulfelder2012forecasting, out-of-sample testing of mass killings theories
remains scarce.[^ewp] Prediction tests are key to adjudicate between rival
explanations, which helps direct academic efforts towards more promising areas
of research [@ward2010perils; @ward2016can]. Moreover, if theoretical
predictions  are unable to explain future events, current findings offer little
guidance to policy-makers. In this regard, identifying robust predictors of
mass killings is essential to improve the accuracy of early warning systems and
increase the reliability of genocide-prevention strategies.

[^ewp]: The Early Warning Project (<https://earlywarningproject.ushmm.org>)
provides a noteworthy attempt to identify countries at risk of genocide. The
Project deserves our highest praise and this paper partially overlaps with
their work. However, their forecasts do not present estimates for variable
importance nor partial dependence plots for the most relevant predictors of
genocide. We build on their findings and not only provide our own out-of-sample
forecasts, which can be compared to theirs, but we also assess the relative
impact of the covariates suggested by the specialised literature. 

In this paper, we employ random forests, a machine learning algorithm, to test
the predictive ability of 40 variables seen as strong determinants of mass
killings. Although a small group of variables does increase the predictive
accuracy of our models, most of the factors do not perform well in
out-of-sample forecasts. We find that economic variables are the most
significant predictors of state-sponsored violence, while political and
demographic factors fare poorly in our models. When we assess the marginal
effects of the predictors, we also find that they are mostly non-linear,
showing high-order interactions and complex prediction patterns. Our results
indicate that the literature on mass atrocities would benefit from focusing on
a particular set of structural factors and adopting more flexible modelling
techniques.

We first present a brief overview of the recent scholarship on mass killings
and discuss its main empirical findings. We then explain how the random forest
algorithm allows us to accurately evaluate the predictive power of the
determinants of mass killings indicated by the literature. We proceed to a
discussion of our results and conclude with suggestions for new avenues of
research.

# An Overview of the Correlates of Mass Killings 
\label{sec:literature}


# Modelling Strategy
\label{sec:methods}

To conduct our analysis, we began by surveying the quantitative political
science literature on the causes of government mass killing since Rummel's
(\citeyear{rummel1995democracy}) seminal work on the subject. Counting only
published works, we identified 45 articles which employed logit or probit
models of mass killing onset in a global sample.  We then included all
variables that appeared in at least two of these papers in our data set at the
country-year unit of analysis for all years from 1945 to 2013. The appendix
provides a complete list of the articles we considered and a complete list of
the variables we included in our models. 

We estimated a distributed random forest analysis to see which of the variables
best predict the onset of mass atrocities. Random forests is a machine learning
algorithm that consists of a combination of individual decision trees. In a
classification problem, each decision tree uses a vector of covariates to split
the dependent variable into two increasingly homogeneous parts
\citep{breiman2001statistical}. Random forests avoids over-fitting by growing a
decision tree only to a bootstrap sample of the original data then 

\citep{dietterich1995comparison,ho1998random}. Random forest, in contrast,
avoids this issue by growing a decision tree only to a bootstrap sample of the
original data, selecting random features at each split, then aggregating the
different trees into a single prediction. If the independent variable is
continuous, the algorithm will simply choose the average value of the
predictions as the best candidate; if the covariate is discrete, the majority
class will be employed. The simple procedure of leaving out some data points
and growing separate trees with a random subset of covariates is sufficient to
eliminate the risk of overfitting \citep[9-10]{jones2015exploratory}.

Random forest has many desirable properties, such as "highly accurate
predictions, robustness to noise and outliers, internally unbiased estimate of
the generalisation error, efficient computation, and the ability to handle
large dimensions and many predictors" \citep[7]{muchlinski2015comparing}. Thus,
random forest allows the researcher to estimate very flexible models with
minimal assumptions. Unlike parametric methods such as ordinary least squares
or logistic regressions, the analyst does not have to impose any distributional
form to the data-generating process. As a result, random forest is able to
effectively uncover complex, nonlinear interaction effects in the data without
prespecification \citep{jones2015exploratory,jones2018there}.









\newpage

# Results 
\label{sec:results}

# Conclusion 
\label{sec:conclusion}

\newpage
\setlength{\parindent}{0cm}
\setlength{\parskip}{5pt}
